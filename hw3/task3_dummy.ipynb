{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "task3_dummy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHkuDfWDCQL_"
      },
      "source": [
        "import os.path\n",
        "import torch\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "#!pip install datasets\n",
        "from keras.datasets import mnist\n",
        "from sklearn import datasets\n",
        "import keras\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fizb_9gCyS5",
        "outputId": "e7fd15bf-5626-472e-8825-b67befea14dd"
      },
      "source": [
        "#Loading MNIST dataset\n",
        "\n",
        "# get cpu or gpu device for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "\n",
        "#########################\n",
        "# Data Preparation\n",
        "###\n",
        "\n",
        "# these functions download (if needed) and load MNIST or fashion-MNIST\n",
        "# Note: sometimes the websites providing the data are down...\n",
        "#\n",
        "dataset_path = '~/datasets'\n",
        "batch_size = 100\n",
        "\n",
        "#transform the data into tensor\n",
        "mnist_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
        "\n",
        "\n",
        "#split the dataset into 60000 training and 10000 validation samples\n",
        "#they are already normalized\n",
        "(train_x, train_labels), (test_x, test_labels) = mnist.load_data()\n",
        "\n",
        "#train_x, train_labels, test_x, test_labels = datasets.load_mnist()\n",
        "#train_x, train_labels, test_x, test_labels = datasets.load_fashion_mnist()\n",
        "\n",
        "\n",
        "\n",
        "# normalize data\n",
        "#train_x = datasets.normalize_min_max(train_x, 0., 1.)\n",
        "#test_x = datasets.normalize_min_max(test_x, 0., 1.)\n",
        "\n",
        "# split off a validation set (not used here, but good practice)\n",
        "valid_x = train_x[-10000:, :]\n",
        "train_x = train_x[:-10000, :]\n",
        "valid_labels = train_labels[-10000:]\n",
        "train_labels = train_labels[:-10000]\n",
        "\n",
        "# generate torch tensors\n",
        "train_x = torch.tensor(train_x).to(device)\n",
        "valid_x = torch.tensor(valid_x).to(device)\n",
        "test_x = torch.tensor(test_x).to(device)\n",
        "\n",
        "# add dummy dimension for number of color channels\n",
        "train_x = train_x.unsqueeze(1)\n",
        "valid_x = valid_x.unsqueeze(1)\n",
        "test_x = test_x.unsqueeze(1)\n",
        "\n",
        "# print some summary characteristics of the datasets\n",
        "print(\"Dataset summary:\")\n",
        "print(f\"Train: {train_x.shape}\")\n",
        "print(f\"Valid: {valid_x.shape}\")\n",
        "print(f\"Test : {test_x.shape}\")\n",
        "\n",
        "# extract number of training data points, number of color channels, and number of data features\n",
        "#train_N, train_C, train_D = train_x.shape\n",
        "train_N = train_x.shape[0]\n",
        "train_C = train_x.shape[1]\n",
        "train_D = train_x.shape[2]\n",
        "# compute image size from number of data features\n",
        "imgsize = int(np.sqrt(train_D))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Dataset summary:\n",
            "Train: torch.Size([50000, 1, 28, 28])\n",
            "Valid: torch.Size([10000, 1, 28, 28])\n",
            "Test : torch.Size([10000, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnEk2WBnDHmz"
      },
      "source": [
        "###########################################\n",
        "class MLPDecoder(torch.nn.Module):\n",
        "    def __init__(self, num_var, num_latent, num_neurons, var=0.05):\n",
        "        super(MLPDecoder, self).__init__()\n",
        "\n",
        "        self.num_var = num_var\n",
        "        self.num_latent = num_latent\n",
        "        self.num_neurons = num_neurons\n",
        "        self.var = var\n",
        "\n",
        "        # generate hidden layers\n",
        "        # E.g., if num_neurons = [500, 1000, 500], then three hidden layers are generated,\n",
        "        # with 500, 1000 and 400 neurons, respectively.\n",
        "        layers = []\n",
        "        num_units = [num_latent] + num_neurons\n",
        "        for n_prev, n_next in zip(num_units[0:-1], num_units[1:]):\n",
        "            layers.append(torch.nn.Linear(n_prev, n_next))\n",
        "            layers.append(torch.nn.ReLU())\n",
        "            #layers.append(torch.nn.Conv2d(64, 128, 5,1,2))\n",
        "            # layers.append(torch.nn.BatchNorm1d(num_features=n_next))\n",
        "            #layers.append(torch.nn.Conv2d(1, 64, 5,1,2))\n",
        "  \n",
        "        self.layers = torch.nn.ModuleList(layers)\n",
        "        # generate output layers, mu\n",
        "        self.mu = torch.nn.Linear(num_hidden[-1], num_var)\n",
        "\n",
        "    def forward(self, z):\n",
        "        res = z\n",
        "        for layer in self.layers:\n",
        "            res = layer(res)\n",
        "        mu = self.mu(res)\n",
        "        return mu\n",
        "        \n",
        "    def sample(self, N, convert_to_numpy=False, suppress_noise=True):\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(N, self.num_latent, device=device)\n",
        "            mu = self.forward(z)\n",
        "            x = mu\n",
        "            # the conditional VAE distribution is isotropic Gaussian, hence we just add noise when sampling it\n",
        "            # for images, one might want to suppress this\n",
        "            if not suppress_noise:\n",
        "                x += np.sqrt(self.var) * torch.randn(N, self.num_var, device=device)\n",
        "\n",
        "        if convert_to_numpy:\n",
        "            z = z.cpu().numpy()\n",
        "            x = x.cpu().numpy()\n",
        "        return x, z"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ieHdPA6DU27"
      },
      "source": [
        "#####################################\n",
        "class MLPEncoder(torch.nn.Module):\n",
        "    def __init__(self, num_var, num_latent, num_neurons):\n",
        "        super(MLPEncoder, self).__init__()\n",
        "\n",
        "        self.num_var = num_var\n",
        "        self.num_latent = num_latent\n",
        "        self.num_neurons = num_neurons\n",
        "\n",
        "        layers = []\n",
        "        num_units = [num_var] + num_neurons\n",
        "        for n_prev, n_next in zip(num_units[0:-1], num_units[1:]):\n",
        "            # layers.append(torch.nn.BatchNorm1d(num_features=n_next))\n",
        "            #layers.append(torch.nn.Conv2d(1, 64, 5,1,2))\n",
        "            #layers.append(torch.nn.ReLU())\n",
        "            #layers.append(torch.nn.Conv2d(64, 128, 5,1,2))\n",
        "            #layers.append(torch.nn.ReLU())\n",
        "            #layers.append(nn.MaxPool2d(2))\n",
        "            layers.append(torch.nn.Linear(n_prev, n_next))\n",
        "            layers.append(torch.nn.ReLU())\n",
        "        self.layers = torch.nn.ModuleList(layers)\n",
        "\n",
        "        # generate output layers, mu and var\n",
        "        self.mu = torch.nn.Linear(num_neurons[-1], num_latent)\n",
        "        self.var = torch.nn.Linear(num_neurons[-1], num_latent)\n",
        "        self.var_act = torch.nn.Softplus()\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "        for layer in self.layers:\n",
        "            res = layer(res)\n",
        "        mu = self.mu(res)\n",
        "        var = self.var_act(self.var(res))\n",
        "        return mu, var"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyyeRynVDXkz",
        "outputId": "6fb1a7f4-390f-4fc0-a4be-24bb658a190c"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# training params\n",
        "# MNIST has 784 pixels\n",
        "# we are using a fixed variance for the decoder\n",
        "# the variance can be also made an output of the decoder, see lecture slides,\n",
        "# but training becomes trickier and somewhat \"brittle\"\n",
        "\n",
        "var_x = 0.05\n",
        "num_latent = 50\n",
        "num_hidden = [1000, 1000]\n",
        "batch_size = 50\n",
        "num_epochs = 2\n",
        "decoder = MLPDecoder(train_C, num_latent, num_hidden, var=var_x).to(device)\n",
        "encoder = MLPEncoder(train_C, num_latent, num_hidden).to(device)\n",
        "\n",
        "print(decoder)\n",
        "print(encoder)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLPDecoder(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=50, out_features=1000, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (mu): Linear(in_features=1000, out_features=1, bias=True)\n",
            ")\n",
            "MLPEncoder(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=1, out_features=1000, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (mu): Linear(in_features=1000, out_features=50, bias=True)\n",
            "  (var): Linear(in_features=1000, out_features=50, bias=True)\n",
            "  (var_act): Softplus(beta=1, threshold=20)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "2gv0htk-ElZP",
        "outputId": "7195fdcd-6a8b-4506-b3da-f004e59f86de"
      },
      "source": [
        "optimizer = torch.optim.Adam(list(decoder.parameters()) + list(encoder.parameters()), lr=0.0001)\n",
        "\n",
        "ELBO_history = []\n",
        "for epoch in range(num_epochs):\n",
        "    # make batches of training indices\n",
        "    shuffled_idx = torch.randperm(50000)\n",
        "    idx_batches = shuffled_idx.split(batch_size)\n",
        "\n",
        "    sum_neg_ELBO = 0.0\n",
        "    for batch_count, idx in enumerate(idx_batches):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_x = train_x[idx, :]\n",
        "        #batch_x = batch_x.float()\n",
        "        # batch_mu_z: batch_size, num_latent\n",
        "        # batch_var_z: batch_size, num_latent\n",
        "        batch_mu_z, batch_var_z = encoder(batch_x)\n",
        "\n",
        "        # sample z, using the \"reparametrization trick\"\n",
        "        batch_z = batch_mu_z + torch.sqrt(batch_var_z) * torch.randn(batch_var_z.shape, device=device)\n",
        "\n",
        "        # mu_x: batch_size, D\n",
        "        mu_x = decoder(batch_z)\n",
        "\n",
        "        # squared distances between mu_x and batch_x\n",
        "        d2 = (mu_x - batch_x) ** 2\n",
        "        # Gaussian likelihood: 1/sqrt(2*pi*var) exp(-0.5 * (mu-x)**2 / var)\n",
        "        # Thus, log-likelihood = -0.5 * ( log(2*pi*var) + (mu-x)**2 / var )\n",
        "        log_p = -0.5 * torch.sum(np.log(decoder.var * 2 * np.pi) + d2 / decoder.var)\n",
        "        KL = -0.5 * torch.sum(1 + torch.log(batch_var_z) - batch_mu_z**2 - batch_var_z)\n",
        "\n",
        "        # we want to maximize the ELBO, hence minimize the negative ELBO\n",
        "        negative_ELBO = -log_p + KL\n",
        "        negative_ELBO.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sum_neg_ELBO += negative_ELBO\n",
        "\n",
        "    mean_neg_ELBO = sum_neg_ELBO / train_x.shape[0]\n",
        "    print('epoch {}   mean negative ELBO = {}'.format(epoch, mean_neg_ELBO))\n",
        "    ELBO_history.append(mean_neg_ELBO)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        with torch.no_grad():\n",
        "            # sample from the VAE\n",
        "            x, z = decoder.sample(5)\n",
        "\n",
        "            # encode some samples\n",
        "            mu_z, var_z = encoder(train_x[0:5, :])\n",
        "            z_encoded = mu_z + torch.sqrt(var_z) * torch.randn(5, num_latent, device=device)\n",
        "\n",
        "            # decode the samples\n",
        "            x_decoded = decoder(z_encoded)\n",
        "\n",
        "            # save images\n",
        "            plot_img = np.stack((train_x[0:5, :].detach().cpu().numpy(),\n",
        "                                 x_decoded.detach().cpu().numpy(),\n",
        "                                 x.detach().cpu().numpy()))\n",
        "            plot_img = np.reshape(plot_img, (15, 28, 28))\n",
        "            file_name = os.path.join('img_vae', 'samples_{}.png'.format(epoch))\n",
        "            datasets.save_image_stack(plot_img, 3, 5, file_name, margin = 3)\n",
        "\n",
        "        plt.figure(1)\n",
        "        plt.clf()\n",
        "        plt.plot(ELBO_history)\n",
        "        plt.savefig(os.path.join('img_vae', 'elbo.png'))\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-cdd31849d003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# batch_mu_z: batch_size, num_latent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# batch_var_z: batch_size, num_latent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbatch_mu_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_var_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# sample z, using the \"reparametrization trick\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-223c35e64a04>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1400x28 and 1x1000)"
          ]
        }
      ]
    }
  ]
}